{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requests and BeautifulSoup libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openpyxl\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 freeze > requirements.txt  # Python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL of the website\n",
    "url = \"https://www.phei.co.id/Data/HPW-dan-Imbal-Hasil\"\n",
    "\n",
    "response = requests.get(url)\n",
    "html_response = response.content\n",
    "text_find = response.text\n",
    "df_list = pd.read_html(html_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20-Januari-2025'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_ = re.search('<div id=\"dnn_ctr1477_GovernmentBondBenchmark_idIGSYC_tdTgl\">', text_find).start()\n",
    "date_yc = text_find[start_ :100+start_]\n",
    "date_yc = date_yc.split(' ')[-2]\n",
    "split = date_yc.find('<')\n",
    "clean_date = date_yc[:split]\n",
    "clean_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20-Januari-2025'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if int(clean_date.split('-')[0]) < 10:\n",
    "    cleaner_date = clean_date.split('-')\n",
    "    cleaner_date[0] = '0' + cleaner_date[0]\n",
    "    clean_date = '-'.join(cleaner_date)\n",
    "clean_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_month_number = {\"Januari\": \"01\", \n",
    "                     \"Februari\": \"02\", \n",
    "                     \"Maret\": \"03\", \n",
    "                     \"April\": \"04\", \n",
    "                     \"Mei\": \"05\", \n",
    "                     \"Juni\": \"06\", \n",
    "                     \"Juli\": \"07\", \n",
    "                     \"Agustus\": \"08\", \n",
    "                     \"September\": \"09\", \n",
    "                     \"Oktober\": \"10\", \n",
    "                     \"November\": \"11\", \n",
    "                     \"Desember\": \"12\",}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder /workspaces/SCRAPING-IBPA-DATA/Scrape PHEI/2025-01-Januari created!\n",
      "Folder /workspaces/SCRAPING-IBPA-DATA/Scrape PHEI/2025-01-Januari/image created!\n",
      "Folder /workspaces/SCRAPING-IBPA-DATA/Scrape PHEI/2025-01-Januari/py-image created!\n"
     ]
    }
   ],
   "source": [
    "sub_path = f'/workspaces/SCRAPING-IBPA-DATA/Scrape PHEI/{clean_date.split(\"-\")[2]}-{dict_month_number.get(clean_date.split(\"-\")[1])}-{clean_date.split(\"-\")[1]}'\n",
    "try:\n",
    "    os.makedirs(sub_path)\n",
    "    print(f\"Folder {sub_path} created!\")\n",
    "except FileExistsError:\n",
    "    print(f\"Folder {sub_path} already exists\")\n",
    "\n",
    "sub_path_image = sub_path+'/image'\n",
    "try:\n",
    "    os.makedirs(sub_path_image)\n",
    "    print(f\"Folder {sub_path_image} created!\")\n",
    "except FileExistsError:\n",
    "    print(f\"Folder {sub_path_image} already exists\")\n",
    "\n",
    "sub_path_py_image = sub_path+'/py-image'\n",
    "try:\n",
    "    os.makedirs(sub_path_py_image)\n",
    "    print(f\"Folder {sub_path_py_image} created!\")\n",
    "except FileExistsError:\n",
    "    print(f\"Folder {sub_path_py_image} already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/workspaces/SCRAPING-IBPA-DATA/Scrape PHEI/2025-Januari/image/20-Januari-2025.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m img_location_url \u001b[38;5;241m=\u001b[39m text_find[re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChartPic\u001b[39m\u001b[38;5;124m'\u001b[39m, text_find)\u001b[38;5;241m.\u001b[39mstart():re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChartPic\u001b[39m\u001b[38;5;124m'\u001b[39m, text_find)\u001b[38;5;241m.\u001b[39mstart()\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m200\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m imgURL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.phei.co.id/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mimg_location_url\n\u001b[0;32m----> 4\u001b[0m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgURL\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/workspaces/SCRAPING-IBPA-DATA/Scrape PHEI/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mclean_date\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mclean_date\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/image/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mclean_date\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.jpeg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/urllib/request.py:250\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Handle temporary file setup.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m--> 250\u001b[0m     tfp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m     tfp \u001b[38;5;241m=\u001b[39m tempfile\u001b[38;5;241m.\u001b[39mNamedTemporaryFile(delete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/workspaces/SCRAPING-IBPA-DATA/Scrape PHEI/2025-Januari/image/20-Januari-2025.jpeg'"
     ]
    }
   ],
   "source": [
    "# Save image from Website\n",
    "img_location_url = text_find[re.search('ChartPic', text_find).start():re.search('ChartPic', text_find).start()+200].split(' ')[0][:-1]\n",
    "imgURL = \"https://www.phei.co.id/\"+img_location_url\n",
    "urllib.request.urlretrieve(imgURL,f'/workspaces/SCRAPING-IBPA-DATA/Scrape PHEI/{clean_date.split(\"-\")[2]}-{clean_date.split(\"-\")[1]}/image/{clean_date}.jpeg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, type_df):\n",
    "    copy_df = df.copy()\n",
    "    copy_df.drop(columns = copy_df.columns[[0, -1]], inplace = True)\n",
    "    copy_df['type'] = type_df\n",
    "    return copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbn_data = prepare_data(df_list[2], 'sbn')\n",
    "sbsn_data = prepare_data(df_list[3], 'sbsn')\n",
    "retail_data= prepare_data(df_list[4], 'retail')\n",
    "\n",
    "bond_data = pd.concat((sbn_data, \n",
    "                             sbsn_data,\n",
    "                             retail_data), axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_data.iloc[:,1] /= 100\n",
    "bond_data.iloc[:,2:-1] /= 10000\n",
    "bond_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_data.to_excel(f'/workspaces/NSS-Model/Scrape PHEI/{clean_date.split(\"-\")[2]}-{clean_date.split(\"-\")[1]}/Bond-Data-{clean_date}.xlsx', \n",
    "            sheet_name=clean_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df_list[0],df_list[1]), axis = 0)[['Tenor Year', 'Today']]\n",
    "df['Tenor Year'] /= 10\n",
    "df['Today'] /= 1e6\n",
    "df.rename(columns = {'Today': 'IBPA Yield'}, inplace = True)\n",
    "df.set_index('Tenor Year', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_rate(df):\n",
    "    spot_data = df.values.copy()\n",
    "    for j in range(2,df.shape[0]):\n",
    "        minus = 0\n",
    "        for k in range(1,j):\n",
    "            minus -= spot_data[j]/(1+spot_data[k])**k\n",
    "        spot_data[j] = ((1+df.iloc[j])/(1+minus))**(1/j)-1\n",
    "    return spot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Spot-Rate'] = spot_rate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.index, df['IBPA Yield'], label = 'Yield Curve')\n",
    "plt.plot(df.index, df['Spot-Rate'], label = 'Spot Rate')\n",
    "plt.legend()\n",
    "plt.title(f'YCB and ZCB IDR {clean_date}')\n",
    "plt.grid()\n",
    "plt.savefig(f'/workspaces/NSS-Model/Scrape PHEI/{clean_date.split(\"-\")[2]}-{clean_date.split(\"-\")[1]}/py-image/{clean_date}.jpeg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(f'/workspaces/NSS-Model/Scrape PHEI/{clean_date.split(\"-\")[2]}-{clean_date.split(\"-\")[1]}/Yield-Curve-{clean_date}.xlsx', \n",
    "            sheet_name=clean_date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
